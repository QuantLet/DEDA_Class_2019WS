{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd   \n",
    "import numpy as np \n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define function to get coin data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://blog.cryptocompare.com/cryptocompare-api-quick-start-guide-f7abbd20d260\n",
    "    \n",
    "#This function establishes a request to the online plattform BitFinex:\n",
    "def get_data_spec(coin, date, time_period):\n",
    "    \"\"\" Query the API for the historical price data starting from \"date\". \"\"\"\n",
    "    url = \"https://min-api.cryptocompare.com/data/{}?fsym={}&e=BitFinex&tsym=USD&toTs={}\".format(time_period, coin, date)\n",
    "    r = requests.get(url)\n",
    "    ipdata = r.json()\n",
    "    return ipdata\n",
    "\n",
    "#This function collects the cryptocurrency data from for the specified time period: \n",
    "def get_df_spec(time_period, coin, from_date, to_date):\n",
    "    \"\"\" Get historical price data between two dates. If further apart than query limit then query multiple times. \"\"\"\n",
    "    date = to_date\n",
    "    \n",
    "    holder = []\n",
    "    while date > from_date:\n",
    "        # Now we use the new function to query specific coins\n",
    "        data = get_data_spec(coin, date, time_period) \n",
    "        holder.append(pd.DataFrame(data[\"Data\"]))\n",
    "        \n",
    "        date = data['TimeFrom'] \n",
    "        \n",
    "\n",
    "def compute_Returns(data):\n",
    "    data[\"Average_price\"]=(data[\"close\"]+data[\"open\"])/2\n",
    "    data[\"returns\"]=data[\"Average_price\"].divide(data[\"Average_price\"].shift())-1\n",
    "    data= data.iloc[1:] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get hourly data for 12 coins according to steady coin study, time period 17/18 six month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = ['BTC', 'ETH', 'XRP' ,'BCH', 'LTC' ,'EOS' ,'XMR', 'NEO', 'MIOTA', 'DASH', 'ETC','ZEC'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hourly_df  = {}\n",
    "\n",
    "start_unix = time.mktime(datetime.datetime.strptime(\"01/05/2019\", \"%d/%m/%Y\").timetuple())\n",
    "end_unix   = time.mktime(datetime.datetime.strptime(\"01/11/2019\", \"%d/%m/%Y\").timetuple())\n",
    "\n",
    "errorcoin  = [] # for coins with no data avaliable  \n",
    "\n",
    "for coin in coins:\n",
    "    try:\n",
    "        hourly_df[coin] = compute_Returns(get_df_spec('histohour',coin,  start_unix, end_unix))\n",
    "    except:\n",
    "        print(coin + ': error')\n",
    "        errorcoin.append(coin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. New API for ZEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No keys, only access to public API functions\n"
     ]
    }
   ],
   "source": [
    "import bitfinex\n",
    "#Create api instance of the v2 API\n",
    "api_v2 = bitfinex.bitfinex_v2.api_v2()\n",
    "result = api_v2.candles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = pd.Series(coins).apply(lambda x :x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_size = '1h'\n",
    "# limit = 5000\n",
    "# t_start = datetime.datetime(2017, 11, 1, 0, 0)\n",
    "# t_start = time.mktime(t_start.timetuple()) * 1000\n",
    "# t_stop    = datetime.datetime(2018, 5, 1, 0, 0)\n",
    "# t_stop    = time.mktime(t_stop.timetuple()) * 1000\n",
    "# names = ['time', 'open', 'close', 'high', 'low', 'volume']\n",
    "# for i,n in enumerate(coins):\n",
    "#     pair=n+'usd'\n",
    "#     pair_data = api_v2.candles(symbol=pair, interval=bin_size,  \n",
    "#                            limit=limit, start=t_start, end=t_stop)\n",
    "#     df = pd.DataFrame(pair_data, columns=names)\n",
    "#     df.drop_duplicates(inplace=True)\n",
    "#     df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "#     df.set_index('time', inplace=True)\n",
    "#     df.sort_index(inplace=True)\n",
    "#     compute_Returns(df)\n",
    "#     hourly_df[n] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.3 ms, sys: 12.2 ms, total: 73.6 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = 'zec'\n",
    "pair = c+'usd'  # Currency pair of interest\n",
    "bin_size = '1h' # This will return minute data\n",
    "limit = 5000    # We want the maximum of 5000 data points \n",
    "# Define the start date\n",
    "t_start = datetime.datetime(2017, 11, 1, 0, 0)\n",
    "t_start = time.mktime(t_start.timetuple()) * 1000\n",
    "# Define the end date\n",
    "t_stop    = datetime.datetime(2018, 5, 1, 0, 0)\n",
    "t_stop    = time.mktime(t_stop.timetuple()) * 1000\n",
    "\n",
    "pair_data = api_v2.candles(symbol=pair, interval=bin_size,  \n",
    "                           limit=limit, start=t_start, end=t_stop)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create pandas data frame and clean/format data\n",
    "names = ['time', 'open', 'close', 'high', 'low', 'volume']\n",
    "df = pd.DataFrame(pair_data, columns=names)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "df.set_index('time', inplace=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zec = compute_Returns(df)\n",
    "hourly_df['ZEC'] = zec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>Average_price</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2017-11-01 00:00:00</td>\n",
       "      <td>232.96</td>\n",
       "      <td>231.00</td>\n",
       "      <td>234.02</td>\n",
       "      <td>230.39</td>\n",
       "      <td>479.177701</td>\n",
       "      <td>231.980</td>\n",
       "      <td>-0.005189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-11-01 01:00:00</td>\n",
       "      <td>230.99</td>\n",
       "      <td>231.09</td>\n",
       "      <td>231.66</td>\n",
       "      <td>228.82</td>\n",
       "      <td>409.477664</td>\n",
       "      <td>231.040</td>\n",
       "      <td>-0.004052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-11-01 02:00:00</td>\n",
       "      <td>230.25</td>\n",
       "      <td>230.43</td>\n",
       "      <td>231.54</td>\n",
       "      <td>229.51</td>\n",
       "      <td>122.662979</td>\n",
       "      <td>230.340</td>\n",
       "      <td>-0.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-11-01 03:00:00</td>\n",
       "      <td>230.42</td>\n",
       "      <td>228.88</td>\n",
       "      <td>230.87</td>\n",
       "      <td>228.01</td>\n",
       "      <td>621.325692</td>\n",
       "      <td>229.650</td>\n",
       "      <td>-0.002996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017-11-01 04:00:00</td>\n",
       "      <td>229.46</td>\n",
       "      <td>227.55</td>\n",
       "      <td>229.47</td>\n",
       "      <td>227.33</td>\n",
       "      <td>551.834344</td>\n",
       "      <td>228.505</td>\n",
       "      <td>-0.004986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-04-30 18:00:00</td>\n",
       "      <td>288.64</td>\n",
       "      <td>287.22</td>\n",
       "      <td>290.60</td>\n",
       "      <td>287.02</td>\n",
       "      <td>348.976872</td>\n",
       "      <td>287.930</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-04-30 19:00:00</td>\n",
       "      <td>288.11</td>\n",
       "      <td>290.17</td>\n",
       "      <td>290.51</td>\n",
       "      <td>286.28</td>\n",
       "      <td>205.714753</td>\n",
       "      <td>289.140</td>\n",
       "      <td>0.004202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-04-30 20:00:00</td>\n",
       "      <td>290.27</td>\n",
       "      <td>289.12</td>\n",
       "      <td>292.00</td>\n",
       "      <td>288.84</td>\n",
       "      <td>248.341325</td>\n",
       "      <td>289.695</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-04-30 21:00:00</td>\n",
       "      <td>289.99</td>\n",
       "      <td>285.59</td>\n",
       "      <td>289.99</td>\n",
       "      <td>285.00</td>\n",
       "      <td>303.514187</td>\n",
       "      <td>287.790</td>\n",
       "      <td>-0.006576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-04-30 22:00:00</td>\n",
       "      <td>286.05</td>\n",
       "      <td>283.57</td>\n",
       "      <td>287.75</td>\n",
       "      <td>283.50</td>\n",
       "      <td>142.997999</td>\n",
       "      <td>284.810</td>\n",
       "      <td>-0.010355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4341 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open   close    high     low      volume  \\\n",
       "time                                                              \n",
       "2017-11-01 00:00:00  232.96  231.00  234.02  230.39  479.177701   \n",
       "2017-11-01 01:00:00  230.99  231.09  231.66  228.82  409.477664   \n",
       "2017-11-01 02:00:00  230.25  230.43  231.54  229.51  122.662979   \n",
       "2017-11-01 03:00:00  230.42  228.88  230.87  228.01  621.325692   \n",
       "2017-11-01 04:00:00  229.46  227.55  229.47  227.33  551.834344   \n",
       "...                     ...     ...     ...     ...         ...   \n",
       "2018-04-30 18:00:00  288.64  287.22  290.60  287.02  348.976872   \n",
       "2018-04-30 19:00:00  288.11  290.17  290.51  286.28  205.714753   \n",
       "2018-04-30 20:00:00  290.27  289.12  292.00  288.84  248.341325   \n",
       "2018-04-30 21:00:00  289.99  285.59  289.99  285.00  303.514187   \n",
       "2018-04-30 22:00:00  286.05  283.57  287.75  283.50  142.997999   \n",
       "\n",
       "                     Average_price   returns  \n",
       "time                                          \n",
       "2017-11-01 00:00:00        231.980 -0.005189  \n",
       "2017-11-01 01:00:00        231.040 -0.004052  \n",
       "2017-11-01 02:00:00        230.340 -0.003030  \n",
       "2017-11-01 03:00:00        229.650 -0.002996  \n",
       "2017-11-01 04:00:00        228.505 -0.004986  \n",
       "...                            ...       ...  \n",
       "2018-04-30 18:00:00        287.930  0.001827  \n",
       "2018-04-30 19:00:00        289.140  0.004202  \n",
       "2018-04-30 20:00:00        289.695  0.001919  \n",
       "2018-04-30 21:00:00        287.790 -0.006576  \n",
       "2018-04-30 22:00:00        284.810 -0.010355  \n",
       "\n",
       "[4341 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge columns for different coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs_on_column(dataframes, labels, col):\n",
    "    '''Merge a single column of each dataframe into a new combined dataframe'''\n",
    "    series_dict = {}\n",
    "    for index in range(len(dataframes)):\n",
    "        series_dict[labels[index]] = dataframes[index][col]\n",
    "        \n",
    "    return pd.DataFrame(series_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyPrice = merge_dfs_on_column(list(hourly_df.values()), list(hourly_df.keys()), 'Average_price')\n",
    "\n",
    "hourlyReturn= merge_dfs_on_column(list(hourly_df.values()), list(hourly_df.keys()),'returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyPrice.to_csv('1718hourlyPrice_withZEC.csv')\n",
    "hourlyReturn.to_csv('1718hourlyReturn_withZEC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Macro Index \n",
    "\n",
    "### S&P 500\n",
    "\n",
    "S&P 500 index get in https://www.investing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('./Data Input/S&P 500 Historical Data.csv')\n",
    "\n",
    "from datetime import datetime\n",
    "# convert str to datetime\n",
    "sp500.Date = sp500.Date.apply(lambda x: pd.to_datetime(datetime.strptime(x, '%b %d, %Y')))\n",
    "\n",
    "# generate hourly time index \n",
    "time_idx = pd.date_range(sp500.Date.iloc[-1], sp500.Date[0], freq=\"1h\")\n",
    "\n",
    "# set time as index\n",
    "sp500.set_index('Date',inplace=True)\n",
    "\n",
    "# reverse dataframe, now the date is ascending\n",
    "sp500 = sp500[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with new hourly idx\n",
    "df         = pd.DataFrame(time_idx)\n",
    "df.columns =['Datetime']\n",
    "df.set_index('Datetime',inplace=True)\n",
    "df['sp500']= sp500['Price']\n",
    "# fill nan with prescending value \n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sp500']=df['sp500'].str.replace(',', '')\n",
    "df.sp500   = df.sp500.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX\n",
    "\n",
    "http://www.cboe.com/products/vix-index-volatility/vix-options-and-futures/vix-index/vix-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix = pd.read_csv('./Data Input/vixcurrent.csv')\n",
    "vix.columns = vix.iloc[0].values\n",
    "vix.drop(0,inplace=True)\n",
    "vix.Date =vix.Date.apply(lambda x: pd.to_datetime(datetime.strptime(x, '%m/%d/%Y')))\n",
    "vix.set_index('Date',inplace= True)\n",
    "vix = vix.astype(float)\n",
    "vix['Price'] =(vix['VIX Open']+vix['VIX Close'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vix']=vix['Price']\n",
    "# fill nan with prescending value \n",
    "df = df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./macro1718.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
